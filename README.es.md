# ğŸ¥‡ AnÃ¡lisis cuantitativo del oro: un enfoque cientÃ­fico del sentimiento del mercado y las LSTM

> **AnÃ¡lisis de Sentimientos NLP Ã— Modelado de Series Temporales con LSTM**  
> Bootcamp Talento-Tech 2025-2 Â· Universidad de Antioquia Â· MedellÃ­n, Colombia

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Estado: Retrospectiva](https://img.shields.io/badge/Estado-Retrospectiva%20TÃ©cnica-orange.svg)](#5-anÃ¡lisis-retrospectivo-y-deuda-tÃ©cnica)

### ğŸ‘‰ [English Version here](README.md)

---

## Tabla de Contenidos

1. [Resumen del Proyecto](#1-resumen-del-proyecto)
2. [El Equipo: FÃ­sicos con Mentalidad de IngenierÃ­a](#2-el-equipo-fÃ­sicos-con-mentalidad-de-ingenierÃ­a)
3. [Estructura Modular por Dominios](#3-estructura-modular-por-dominios)
4. [Inicio RÃ¡pido](#4-inicio-rÃ¡pido)
5. [AnÃ¡lisis Retrospectivo y Deuda TÃ©cnica](#5-anÃ¡lisis-retrospectivo-y-deuda-tÃ©cnica)
6. [Lecciones Aprendidas](#6-lecciones-aprendidas)
7. [Hoja de Ruta: La EvoluciÃ³n Lakehouse](#7-hoja-de-ruta-la-evoluciÃ³n-lakehouse)
8. [Estructura del Proyecto](#8-estructura-del-proyecto)

---

## 1. Resumen del Proyecto

Â¿Puede el sentimiento de las noticias financieras **predecir** los movimientos del precio del oro?

Este proyecto construye un pipeline de extremo a extremo que:
- **Extrae** ~189.000 titulares del Wall Street Journal (2016â€“2025).
- **Filtra** ~18.700 artÃ­culos relacionados con oro mediante heurÃ­sticas de palabras clave.
- **Califica** cada titular con **FinBERT** (ProsusAI/finbert), un modelo transformer afinado para sentimiento financiero.
- **Detecta anomalÃ­as** en los datos del precio del oro usando mÃ©todos estadÃ­sticos.
- **Prueba causalidad** entre sentimiento y precio mediante Causalidad de Granger.
- **Predice** el precio diario de cierre del oro con redes LSTM â€” comparando un modelo base (solo precio) contra un modelo enriquecido con sentimiento.

**Hallazgo clave:** Integrar features de sentimiento FinBERT en el LSTM mejorÃ³ la precisiÃ³n predictiva, aunque la seÃ±al causal es matizada. El anÃ¡lisis completo, incluyendo las advertencias estadÃ­sticas, estÃ¡ documentado a lo largo de 8 notebooks.

---

## 2. El Equipo: FÃ­sicos con Mentalidad de IngenierÃ­a

### Dupla de Liderazgo y Gobierno TÃ©cnico

| Rol | Miembro | Responsabilidad | CertificaciÃ³n |
| :--- | :--- | :--- | :--- |
| **LÃ­der TÃ©cnico e Integrador** | Pablo Sanchez *(FÃ­sico â€“ UdeA)* | UnificaciÃ³n del pipeline, arquitectura de 8 notebooks, DetecciÃ³n de anomalÃ­as, auditorÃ­a post-proyecto | [Verificar Talento Tech ğŸ†](https://www.auco.ai/verify/?code=HXKAW5DL5W) |
| **Co-LÃ­der y Analista EstadÃ­stico** | Jose Ortiz *(FÃ­sico â€“ UdeA)* | Infraestructura de Web scraping, anÃ¡lisis de Causalidad de Granger, validaciÃ³n de datos | [Verificar Talento Tech ğŸ†](PONER_URL_DE_JOSE) |

Pablo y Jose fueron la **dupla tÃ©cnica central** del proyecto. Pablo se encargÃ³ de que el pipeline corriera de punta a punta; Jose se encargÃ³ de que cada resultado estadÃ­stico fuera defendible. Este esquema â€” donde uno hace las veces de Ingeniero de Plataforma y el otro de Analista Cuantitativo â€” blindÃ³ la integridad de los datos en todo el flujo, desde la extracciÃ³n hasta el modelo final.

### El Equipo Completo

| Miembro | FormaciÃ³n | ContribuciÃ³n |
|---------|-----------|-------------|
| David Alava | FÃ­sica â€“ UdeA | Especialista NLP (implementaciÃ³n de FinBERT) |
| Sebastian Agudelo | FÃ­sica â€“ UdeA | Especialista NLP (implementaciÃ³n de FinBERT) |
| Dayana Henao | FÃ­sica â€“ UdeA | Ingeniera ML (LSTM y EDA de Precios del Oro) |
| Luis Vera | IngenierÃ­a Forestal | Especialista en EDA (anÃ¡lisis de noticias) |
| Michael Tarazona | IngenierÃ­a ElÃ©ctrica â€“ UdeA | Apoyo general |

> **Sobre la asignaciÃ³n de roles:** Cada persona recibiÃ³ su rol por lo que sabÃ­a hacer, no por lo que decÃ­a su tÃ­tulo. Luis, siendo Ingeniero Forestal, liderÃ³ el EDA de Noticias porque su capacidad analÃ­tica lo respaldaba. En un equipo de fÃ­sicos, eso se respeta.

---

## 3. Estructura Modular por Dominios

Este proyecto **no** es un notebook gigante donde todo estÃ¡ revuelto. Es una **estructura modular donde cada notebook corresponde a un dominio tÃ©cnico concreto**, con un responsable claro y contratos de entrada/salida definidos (archivos CSV y JSON).

Â¿Por quÃ© lo diseÃ±amos asÃ­? Porque Ã©ramos 7 personas trabajando en paralelo. Si todo vivÃ­a en un solo archivo, los conflictos de merge y las dependencias cruzadas nos habrÃ­an frenado. Cada notebook es una pieza independiente que recibe datos del paso anterior y entrega resultados al siguiente â€” como un mini-servicio, pero a escala de bootcamp.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EL PIPELINE DE INTEGRACIÃ“N                    â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“¥ INGESTA           ğŸ“Š EXPLORACIÃ“N       ğŸ”¬ ANÃLISIS         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ 01       â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ 02       â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ 04           â”‚      â”‚
â”‚  â”‚ Carga    â”‚        â”‚ EDA      â”‚        â”‚ DetecciÃ³n    â”‚      â”‚
â”‚  â”‚ Datos    â”‚        â”‚ Precios  â”‚        â”‚ AnomalÃ­as    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚              â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ 03       â”‚               â”‚              â”‚
â”‚                      â”‚ EDA      â”‚               â”‚              â”‚
â”‚                      â”‚ Noticias â”‚               â”‚              â”‚
â”‚                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜               â”‚              â”‚
â”‚                           â”‚                     â”‚              â”‚
â”‚  ğŸ§  NLP                  â”‚         ğŸ“ˆ MODELADO  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ 05           â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚ 06                 â”‚      â”‚
â”‚  â”‚ FinBERT      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ CorrelaciÃ³n &      â”‚      â”‚
â”‚  â”‚ Sentimiento  â”‚                 â”‚ Causalidad Granger â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                            â”‚                   â”‚
â”‚  ğŸ¤– PREDICCIÃ“N           ğŸ“‹ SÃNTESIS       â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                   â”‚
â”‚  â”‚ 07           â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”¤ Dataset     â”‚â—€â”€â”€â”˜                   â”‚
â”‚  â”‚ Modelos LSTM â”‚        â”‚ Integrado   â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚         â”‚                                                      â”‚
â”‚         â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                              â”‚
â”‚  â”‚ 08           â”‚                                              â”‚
â”‚  â”‚ SÃ­ntesis &   â”‚                                              â”‚
â”‚  â”‚ Resultados   â”‚                                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| # | Notebook | Responsable(s) | PropÃ³sito |
|---|----------|----------------|-----------|
| 01 | IntroducciÃ³n y Carga de Datos | Pablo | Carga de barras horarias + noticias; resampleo diario; validaciÃ³n de alineaciÃ³n |
| 02 | EDA Precios del Oro | Dayana | AnÃ¡lisis estadÃ­stico, pruebas de estacionariedad, descomposiciÃ³n estacional |
| 03 | EDA Noticias WSJ | Luis | Volumen de noticias, cobertura temporal, filtrado por palabras clave |
| 04 | DetecciÃ³n de AnomalÃ­as | Pablo | DetecciÃ³n de outliers en precios del oro mediante mÃ©todos estadÃ­sticos |
| 05 | AnÃ¡lisis de Sentimientos (FinBERT) | David y Sebastian | Inferencia FinBERT sobre ~18K titulares; agregaciÃ³n diaria |
| 06 | CorrelaciÃ³n y Causalidad | Jose | CorrelaciÃ³n Pearson/Spearman, pruebas de Causalidad de Granger |
| 07 | Modelo LSTM Integrado | Dayana y Pablo | ComparaciÃ³n LSTM base vs. enriquecido con sentimiento |
| 08 | SÃ­ntesis y Resultados | Pablo | GeneraciÃ³n del reporte final, sÃ­ntesis entre notebooks |

---

## 4. Inicio RÃ¡pido

### Prerequisitos
- Python 3.8+
- ~4 GB de espacio en disco (cachÃ© del modelo FinBERT)

### InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/SiririComun/Quantitative-Gold-Analysis.git
cd Quantitative-Gold-Analysis

# 2. Crear y activar un entorno virtual (Recomendado)
python -m venv venv
# En Linux/macOS:
source venv/bin/activate  
# En Windows:
venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Configurar entorno
cp .env.example .env
# Editar .env si los datos no estÃ¡n en la raÃ­z del proyecto
# Por defecto: BASE_DIR=.
```

### EjecuciÃ³n de los Notebooks

```bash
cd unificacion/notebooks
jupyter notebook
```

Ejecutar los notebooks **en orden numÃ©rico** (01 â†’ 08). Cada notebook lee las salidas de los anteriores.

> **âš ï¸ Nota de Portabilidad:** Este proyecto originalmente usaba rutas absolutas hardcodeadas. Estas han sido reemplazadas con configuraciÃ³n basada en variables de entorno mediante `python-dotenv`. Si encuentras problemas con rutas, verifica tu archivo `.env`.

### ğŸ“Š Disponibilidad del conjunto de datos

Para que este repositorio sea ligero, los archivos de datos incluidos aquÃ­ son muestras (las primeras 500 filas). Esto le permite ejecutar los cuadernos y verificar la lÃ³gica del proceso de inmediato.

**Conjunto de datos completo:** si desea reproducir el estudio completo con los aproximadamente 189 000 titulares y el historial de precios completo (aproximadamente 160 MB), puede descargar la base de datos completa aquÃ­: [https://drive.google.com/drive/folders/1osPy3E6g6bIYcpd54menGyOlnp2SlJog?usp=sharing]

---

## 5. AnÃ¡lisis Retrospectivo y Deuda TÃ©cnica

> *"Lo que distingue a un ingeniero senior no es entregar cÃ³digo perfecto, sino saber exactamente dÃ³nde estÃ¡n las grietas y tener un plan para cerrarlas."*

Una vez terminÃ³ el bootcamp, me sentÃ© a revisar el proyecto con ojos de auditor. Lo que sigue no es un intento de esconder las limitaciones del equipo â€” al contrario: es la demostraciÃ³n de que entiendo la distancia entre un prototipo acadÃ©mico y un sistema que pueda correr en producciÃ³n real.

### ğŸ”´ Sesgo de AnticipaciÃ³n (Look-ahead Bias)

**El problema:** En el Notebook 05, las medias mÃ³viles de sentimiento se calculan con `rolling(window=7, center=True)`. Ese `center=True` hace que el valor del dÃ­a *t* use informaciÃ³n de los dÃ­as *t+1, t+2, t+3* â€” es decir, datos del futuro que en la prÃ¡ctica no existirÃ­an al momento de hacer la predicciÃ³n.

**Por quÃ© importa:** Las mÃ©tricas del modelo (RMSE, MAE) pueden verse artificialmente buenas porque el LSTM, de manera indirecta, tuvo acceso a seÃ±ales de sentimiento que aÃºn no habÃ­an ocurrido. En un contexto bancario, esto invalida el backtesting.

**CÃ³mo se corrige:** Usar ventanas estrictamente retrospectivas: `rolling(window=7, center=False)`. La regla es simple â€” todo feature del dÃ­a *t* debe calcularse **solo** con datos disponibles hasta el dÃ­a *t*.

### ğŸŸ¡ DesalineaciÃ³n entre Frecuencias Temporales

**El problema:** Los timestamps de las noticias se reducen a la fecha (`dt.date`) antes de cruzarlos con las barras diarias de precio. Esto pasa por alto dos cosas:
- Una noticia publicada a las 11 PM (despuÃ©s del cierre del mercado) queda asignada al precio de cierre de ese mismo dÃ­a, como si el mercado ya hubiera "reaccionado".
- Los precios estÃ¡n en UTC y los timestamps de las noticias no tienen una normalizaciÃ³n explÃ­cita de zona horaria.

**Por quÃ© importa:** Se pueden contaminar features del mismo dÃ­a con informaciÃ³n que no estaba disponible durante la sesiÃ³n de trading. En una mesa de operaciones, eso genera decisiones basadas en datos falsos.

**CÃ³mo se corrige:** Normalizar todo a UTC, usar calendarios de mercado (`exchange_calendars`) y hacer joins tipo *as-of* â€” que asignan cada noticia a la **siguiente** barra de precio disponible, no a la del mismo dÃ­a.

### ğŸŸ¡ PÃ©rdida Silenciosa de Datos por Inner Join

**El problema:** En el Notebook 06, la integraciÃ³n usa `df_precios.join(df_sentimientos, how='inner')`. Esto descarta sin aviso cualquier fecha donde no existan datos en ambos DataFrames.

**Por quÃ© importa:** Los dÃ­as de trading sin cobertura de noticias quedan por fuera del anÃ¡lisis. El dataset resultante estÃ¡ sesgado hacia dÃ­as "con eventos", lo cual puede distorsionar tanto las correlaciones como el entrenamiento del LSTM.

**CÃ³mo se corrige:** Usar un left join sobre el eje de precios y manejar el sentimiento faltante de forma explÃ­cita (forward-fill o imputaciÃ³n con valor neutro).

### ğŸŸ¢ Portabilidad (Resuelta)

**El problema:** Todas las rutas apuntaban a `/home/els4nchez/Videos/TECH/...` â€” nadie mÃ¡s podÃ­a correr el proyecto sin editar el cÃ³digo.

**Estado:** âœ… Corregido. Ahora se usa `os.getenv('BASE_DIR')` con `python-dotenv`. Basta con copiar `.env.example` a `.env` y listo.

---

## 6. Lecciones Aprendidas

- **EvoluciÃ³n de Scripting a IngenierÃ­a:** Construimos exitosamente un pipeline LSTM funcional usando Jupyter Notebooks para prototipado rÃ¡pido. AprendÃ­ que esta estructura monolÃ­tica-por-notebook dificulta la modularidad. Las iteraciones futuras refactorizarÃ­an la lÃ³gica de procesamiento de datos en un paquete Python independiente para habilitar pruebas unitarias e integraciÃ³n CI/CD.

- **Agnosticismo de Infraestructura:** El proyecto originalmente dependÃ­a de rutas de archivos locales. Una lecciÃ³n clave fue la necesidad de configuraciÃ³n basada en variables de entorno (principios de la App de 12 Factores) para asegurar que el pipeline funcione de manera idÃ©ntica en la laptop de un desarrollador, un runner de CI o un contenedor en la nube.

- **SeparaciÃ³n de Responsabilidades en ML:** Acoplamos estrechamente la ingenierÃ­a de features con el entrenamiento del modelo. ReconocÃ­ que separar estos en pasos distintos (e.g., usando una herramienta como Apache Airflow o Prefect) permitirÃ­a un mejor manejo de errores, reproducibilidad y procesamiento incremental de datos sin reentrenar el modelo completo.

---

## 7. Hoja de Ruta: La EvoluciÃ³n Lakehouse

Si este proyecto fuera a evolucionar hacia un sistema de grado productivo (e.g., en Bancolombia), la arquitectura seguirÃ­a un patrÃ³n **Lakehouse / Bronce-Plata-Oro**:

| Capa | PropÃ³sito | Estado Actual | Objetivo Productivo |
|------|-----------|---------------|---------------------|
| **ğŸ¥‰ Bronce** | Ingesta cruda e inmutable | Archivos CSV en `data/raw/` | Parquet/Delta particionado por fecha en almacenamiento cloud |
| **ğŸ¥ˆ Plata** | Limpio, normalizado, validado | `datos_procesados/*.csv` | ValidaciÃ³n de esquema, normalizaciÃ³n UTC, puertas de calidad de datos |
| **ğŸ¥‡ Oro** | Features listos para negocio | `datos_integrados_*.csv` | Feature store con correcciÃ³n point-in-time y trazabilidad de linaje |

### Componentes Clave de ProducciÃ³n

- **Feature Store** (e.g., Feast): Garantizar que cada feature para el tiempo *t* se compute usando solo datos disponibles en o antes de *t*. Esto elimina el sesgo de anticipaciÃ³n por diseÃ±o.
- **OrquestaciÃ³n de Pipelines** (e.g., Airflow/Prefect): Reemplazar la ejecuciÃ³n manual de notebooks con DAGs versionados y testeables.
- **Seguimiento de Experimentos** (e.g., MLflow): Reemplazar los `print()` con logging estructurado de mÃ©tricas.
- **ContenerizaciÃ³n** (Docker + CI/CD): Asegurar reproducibilidad entre entornos.

---

## 8. Estructura del Proyecto

```
â”œâ”€â”€ .env.example                          # Plantilla de entorno (BASE_DIR=. por defecto)
â”œâ”€â”€ .github/                              # Metadatos del repo (workflows, contexto)
â”œâ”€â”€ README.md                             # VersiÃ³n en inglÃ©s
â”œâ”€â”€ README.es.md                          # Este archivo (EspaÃ±ol)
â”œâ”€â”€ requirements.txt                      # Dependencias raÃ­z
â”œâ”€â”€ filtrado_noticias.py                  # Script de filtrado de titulares WSJ
â”œâ”€â”€ data/                                 # Carpeta local (contenido se mantiene local/manual)
â”‚   â”œâ”€â”€ raw/                              # Datos crudos + muestras (local)
â”‚   â””â”€â”€ processed/                        # ArtÃ­culos filtrados + muestras (local)
â”œâ”€â”€ datos_horas/                          # Barras horarias del precio del oro (local)
â””â”€â”€ unificacion/
    â”œâ”€â”€ requirements.txt                  # Dependencias del pipeline
    â”œâ”€â”€ notebooks/
    â”‚   â”œâ”€â”€ 01_Introduccion_y_Carga_de_Datos.ipynb
    â”‚   â”œâ”€â”€ 02_EDA_Precios_Oro.ipynb
    â”‚   â”œâ”€â”€ 03_EDA_Noticias_WSJ.ipynb
    â”‚   â”œâ”€â”€ 04_Deteccion_Anomalias.ipynb
    â”‚   â”œâ”€â”€ 05_Analisis_Sentimientos_FinBERT.ipynb
    â”‚   â”œâ”€â”€ 06_Correlacion_y_Causalidad.ipynb
    â”‚   â”œâ”€â”€ 07_Modelo_LSTM_Integrado.ipynb
    â”‚   â””â”€â”€ 08_Sintesis_y_Resultados.ipynb
    â”œâ”€â”€ datos_procesados/                 # Salidas procesadas (local/generadas)
    â”œâ”€â”€ modelos/                          # Modelos LSTM entrenados (.keras) (local)
    â”œâ”€â”€ figuras/                          # GrÃ¡ficos interactivos Plotly (local)
    â””â”€â”€ informes/                         # Tablas resumen (local)
```

---

## Agradecimientos

Este proyecto fue desarrollado como parte del **Bootcamp Talento-Tech (2025-2)** en colaboraciÃ³n con la **Universidad de Antioquia**, MedellÃ­n. Agradecimiento especial a los instructores del bootcamp por crear el ambiente que hizo posible esta colaboraciÃ³n cientÃ­fica.

La auditorÃ­a arquitectÃ³nica post-proyecto fue realizada de forma independiente como preparaciÃ³n para el programa **Bancolombia Talento B**, aplicando estÃ¡ndares de ingenierÃ­a empresarial a un prototipo de bootcamp.

---

<p align="center">
  <i>Construido por fÃ­sicos. Integrado por un ingeniero en formaciÃ³n. Auditado con honestidad.</i>
</p>
